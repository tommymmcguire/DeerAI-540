{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQXEVVxjNktYaNBX0+McXY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tommymmcguire/DeerAI-540/blob/main/classical_approach_deer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_LmE0W12Poz",
        "outputId": "8038d975-5e92-4ef0-d90c-fa82d722c49f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Remove Colab default sample_data\n",
        "!rm -r ./sample_data\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "def resize_image(image, target_height=500):\n",
        "    \"\"\"Resize images while keeping aspect ratio.\"\"\"\n",
        "    h, w = image.shape[:2]\n",
        "    scaling_factor = target_height / h\n",
        "    return cv2.resize(image, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "def extract_shape_features(image_path):\n",
        "    \"\"\"Extract basic shape features related to the aspect ratio of the deer's silhouette.\"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    image = resize_image(image)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if contours:\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "        aspect_ratio = w / h\n",
        "        return [aspect_ratio]\n",
        "    return [0]  # Return a list with a single feature value of 0 if no contour is found\n",
        "\n",
        "def process_image(data):\n",
        "    filename, directory = data\n",
        "    try:\n",
        "        image_path = os.path.join(directory, filename)\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg')):\n",
        "            aspect_ratio = extract_shape_features(image_path)[0]  # Directly get the scalar value\n",
        "            matches = re.findall(r'\\d+', filename)\n",
        "            if not matches:\n",
        "                raise ValueError(f\"No age found in filename: {image_path}\")\n",
        "            age = float(matches[-1])\n",
        "            return aspect_ratio, age  # Return scalar value for aspect_ratio\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {filename}: {e}\")\n",
        "    return 0, 0  # Return default values in case of an error\n",
        "\n",
        "def prepare_dataset_parallel(directory):\n",
        "    tasks = [(filename, directory) for filename in os.listdir(directory) if filename.lower().endswith(('.jpg', '.jpeg'))]\n",
        "    features, ages = [], []\n",
        "    with ProcessPoolExecutor(max_workers=4) as executor:  # Limiting the number of workers to 4\n",
        "        futures = {executor.submit(process_image, task): task for task in tasks}\n",
        "        for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Processing images in {directory}\"):\n",
        "            aspect_ratio, age = future.result()\n",
        "            features.append([aspect_ratio])  # Make sure to append as a list to keep it 2D\n",
        "            ages.append(age)\n",
        "    # Ensure features are correctly shaped as (n_samples, n_features)\n",
        "    return np.array(features).reshape(-1, 1), np.array(ages)\n",
        "\n",
        "# Assuming the paths to your dataset directories are correctly set\n",
        "train_dir = './drive/MyDrive/CKWRI Deer Photos/datasets/train'\n",
        "val_dir = './drive/MyDrive/CKWRI Deer Photos/datasets/val'\n",
        "test_dir = './drive/MyDrive/CKWRI Deer Photos/datasets/test'\n",
        "\n",
        "# Prepare datasets in parallel\n",
        "X_train, y_train = prepare_dataset_parallel(train_dir)\n",
        "X_val, y_val = prepare_dataset_parallel(val_dir)\n",
        "X_test, y_test = prepare_dataset_parallel(test_dir)\n",
        "\n",
        "# Scaling and SVR model training as before\n",
        "svr_regressor = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
        "svr_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Validate the model\n",
        "y_val_pred = svr_regressor.predict(X_val)\n",
        "val_mse = mean_squared_error(y_val, y_val_pred)\n",
        "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
        "val_rmse = np.sqrt(val_mse)\n",
        "\n",
        "print(f'Validation MSE: {val_mse:.4f}, MAE: {val_mae:.4f}, RMSE: {val_rmse:.4f}')\n",
        "\n",
        "# Test the model\n",
        "y_test_pred = svr_regressor.predict(X_test)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "print(f'Test MSE: {test_mse:.4f}, MAE: {test_mae:.4f}, RMSE: {test_rmse:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIoz-Bf-5RDl",
        "outputId": "08382bb7-6d88-40eb-d7a2-10a11863e78f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images in ./drive/MyDrive/CKWRI Deer Photos/datasets/train: 100%|██████████| 15647/15647 [32:24<00:00,  8.05it/s]\n",
            "Processing images in ./drive/MyDrive/CKWRI Deer Photos/datasets/val: 100%|██████████| 3909/3909 [07:46<00:00,  8.39it/s]\n",
            "Processing images in ./drive/MyDrive/CKWRI Deer Photos/datasets/test: 100%|██████████| 2175/2175 [04:22<00:00,  8.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MSE: 17.4930, MAE: 2.9657, RMSE: 4.1825\n",
            "Test MSE: 17.5321, MAE: 2.9695, RMSE: 4.1871\n"
          ]
        }
      ]
    }
  ]
}